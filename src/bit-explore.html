<article id="explore" class="exhibit jump bleed-inset">
  <div class="exhibit-intro">
    <h2 class="chapter">Explore</h2>
    <small class="exhibit-info exhibit-info-instruct exhibit-info-intro" md inline>
      Explore the installation mockup, drag to move around the space, open points-of-interest marked with **+**
    </small>
    <small class="scroll-roll" style="inset: auto 0 100% 0;">scroll</small>
  </div>
  <input id="exhibit-wrapped" class="exhibit-wrapped" type="checkbox" />
  <input id="exhibit-touring" class="exhibit-touring" type="checkbox" />
  <aside class="exhibit-actions">
    <label for="exhibit-wrapped"
      class="exhibit-wrap icon material-symbols-rounded">
    </label>
    <label for="exhibit-touring"
      class="exhibit-tour icon material-symbols-rounded">
    </label>
  </aside>
  <small class="exhibit-info exhibit-info-instruct exhibit-info-touch" md inline>
    Turn and zoom the space using 2 fingers
  </small>
  <div class="exhibit-demo">
    <video class="exhibit-video exhibit-disc"
      autoplay loop muted controls preload="none"
      src="../media/artizen-s5-artifact.mp4">
    </video>
    <video class="exhibit-video exhibit-wrap"
      autoplay loop muted controls preload="none"
      src="../media/wrap-flow-tile.mp4">
    </video>
  </div>
  <section id="explore-locus" class="exhibit-info jump"
    data-exhibit-camera="PerspectiveCamera0" md>
    <a href="#explore-locus" class="jump-share material-symbols-rounded"></a>

    ## *Locus* is an artwork in progress

    Designed to engage audiences in embodied experiences of meditation, it's being developed for exhibition – as an installation, a free online experience, and a series of unique edition `NFT`{.info aria-description="Non-Fungible Token, a cryptocurrency asset"}s.
  </section>
  <section id="explore-concept"
    class="exhibit-info exhibit-info-flip jump"
    data-exhibit-camera="PerspectiveCamera1" md>
    <a href="#explore-concept" class="jump-share material-symbols-rounded"></a>

    ### Concept and aesthetic

    Millions of fluid particles pass through a translucent human bust – their colours match the anatomy they flow within (skin, bone, tissue), tracing ephemeral hints of forms and colours layered within the volume's depths.

    Reflecting on this fluid motion elicits a meditation on our own subjective sensations (bodily, cognitive, emotional) – each organic, dynamic, interconnected, emergent phenomena.

    Meditation can't be truly be known conceptually or discursively, only by **direct participatory experience** – instilled here by interactive real-time visuals, physics, audio.

    <small>The bust and internal anatomy, clear glass sculptures where particles trace colours, are [3D volumes](https://medium.com/@shrekshao_71662/dual-depth-peeling-implementation-in-webgl-11baa061ba4b){target="_blank"} of [`Signed-Distance Fields`](https://developer.nvidia.com/gpugems/gpugems3/part-v-physics-simulation/chapter-34-signed-distance-fields-using-single-pass-gpu){target="_blank"}.</small>

    <small>The bust forms a hyper-realistic 3D scan of your face using [`Gaussian Splatting`](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/){target="_blank"} technology.</small>
  </section>
  <section id="explore-interact" class="exhibit-info jump"
    data-exhibit-camera="PerspectiveCamera3" md>
    <a href="#explore-interact" class="jump-share material-symbols-rounded"></a>

    ### Interact by your natural motion

    Your natural motions affect the flow – **activity agitates turbulence** to cloud outer surfaces; **stillness settles smooth forms** to reveal intricate inner depths.

    In this way the artwork reveals itself by your still mindful reflection, in contrast to busy activity – as **still water's clearer than an agitated surface**, you see more deeply within.

    <small>Your body's intuitive motion affects the artwork via its camera:</small>
    <br/>
    <small>[`Optical-flow`](https://epok.tech/glsl-optical-flow){target="_blank"} tracks any motions to [influence particle flows](https://youtu.be/ClTmZ3s7Uls){target="_blank"}.</small>
    <br/>
    <small>[`AI` body-tracking](https://codepen.io/mediapipe/full/LYRRYEw){.info aria-description="Artificial Intelligence body-tracking uses AI to interpret a person's form" target="_blank"} mirrors your viewpoint by [the turn of your head](https://youtu.be/u5zUMPnKnGk){target="_blank"} and lets you slice the visuals along your palm's surface.</small>

    <small>[**Peer into the flow**](https://nft.olta.art/project/0x6d24ce4c32e556313b431fb156edf2060680a998){target="_blank"} explores `AI` face-tracking interactions to intuitively mirror your viewpoint – in an [`NFT` series of interactive sketches](https://youtu.be/XagjH3bkQ0s){target="_blank"} supporting and prototyping parts of **Locus**, our crowdfund backers are [rewarded with a random edition](#reward-peer).</small>
  </section>
  <section id="explore-audio" class="exhibit-info jump"
    data-exhibit-camera="PerspectiveCamera2" md>
    <a href="#explore-audio" class="jump-share material-symbols-rounded"></a>

    ### Emergent immersive audio

    Flowing particles **generate audio in real-time**, spatially-mapped to speakers enclosing the space – individual particle sounds culminate into an immersive collective sound; **as the sound of wind moving a leaf is to that of a forest**.

    Dynamically driving sound by the emergent motions of millions of interacting particles in an experimental process – we explore the potential of **procedural audio** to create **aleatoric music**.

    <small>Hear how [aleatoric music](https://youtu.be/cIsewG2g-1g){target="_blank"} can be composed in an emergent process.</small>
  </section>
  <section id="explore-motion" class="exhibit-info exhibit-info-flip jump"
    data-exhibit-camera="PerspectiveCamera4" md>
    <a href="#explore-motion" class="jump-share material-symbols-rounded"></a>

    ### Motion and fluid dynamics

    The hyper-realistic fluid dynamics are driven by `Material Point Method` simulation – a cutting-edge physics method handling multiple forms of matter interacting in one model.

    **Locus** will adapt `MPM`{.info aria-description="Material Point Method physics simulation"} technology for real-time fluid-dynamics on web-platforms – from its origins in high-end film and game fields – and release it as **Open-Source Software**{.info aria-description="Open-Source Software shares access and insights freely with anyone who wants to learn from or adapt these technologies."}.

    <small>See how `MPM` simulates hyper-realistic physics [here](https://youtu.be/tctsShc9Lok){target="_blank"}, [here](https://youtu.be/B_NYFbRzTRQ?t=230){target="_blank"}, and [here](https://youtu.be/9M18rc9-VWU?t=37){target="_blank"}.</small>
  </section>
  <section id="explore-exhibits" class="exhibit-info jump"
    data-exhibit-camera="PerspectiveCamera0" md>
    <a href="#explore-exhibits" class="jump-share material-symbols-rounded"></a>

    ### Exhibited in complementary formats

    **Physical installation:** The main exhibit; a projection on a large circular screen, parting the space between observers and a participant interacting via camera, enclosed by an array of immersive-audio speakers.

    **Online digital:** The free and open exhibit; explored freely anywhere by anyone on their own web-devices, supporting equity of access to the artwork.

    **Collectible editions:** An `NFT` series spanning the artwork's range of aesthetics and themes; **driven by on-chain data**{.info aria-description="Each NFT edition's aesthetics respond to information from its blockchain network, reacting to its owner and how it and the collection are traded"} and collectors' input. Supporters and installation audiences earn rewards that interact with these `NFT` editions.
  </section>
  <small class="exhibit-info exhibit-info-instruct exhibit-info-outro" md inline>
    <small class="scroll-roll" style="inset: 100% 0 auto 0;">scroll</small>
    explore further
  </small>
</article>
